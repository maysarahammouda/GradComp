Vocabluary size: 39
==================================================
|                    Training                    |
==================================================
Epoch Size=  4
batch######## 1
grad[0]: tensor([-0.0002, -0.0005, -0.0006,  ...,  0.0000,  0.0000,  0.0000])
grad[1].shape: torch.Size([3600])
grad[10].shape: torch.Size([39])
***batch_idx***: 1
batch######## 2
grad[0]: tensor([-9.5980e-06,  2.6851e-04,  3.8101e-05,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1].shape: torch.Size([3600])
grad[10].shape: torch.Size([39])
***batch_idx***: 2
batch######## 3
grad[0]: tensor([-0.0010, -0.0005,  0.0001,  ...,  0.0000,  0.0000,  0.0000])
grad[1].shape: torch.Size([3600])
grad[10].shape: torch.Size([39])
***batch_idx***: 3
batch######## 4
grad[0]: tensor([ 0.0000, -0.0004,  0.0002,  ...,  0.0000,  0.0000,  0.0000])
grad[1].shape: torch.Size([3600])
grad[10].shape: torch.Size([39])
***batch_idx***: 4
Train perplexity at epoch 0:    38.02
Epoch Size=  4
Validation perplexity at epoch 0:    34.73
==================================================
|                    Testing                     |
==================================================
Epoch Size=  36
Test Perplexity:    34.75

======================== Done! ========================
