Vocabluary size: 39
==================================================
|                    Training                    |
==================================================
Epoch Size=  8

batch## 1
grad[0]: tensor([ 0.0000, -0.0003, -0.0003,  ...,  0.0000,  0.0000,  0.0000])
grad[1]: tensor([ 2.1651e-06,  2.0497e-07,  3.5994e-06,  ...,  3.6116e-08,
        -4.4187e-08, -1.6756e-07])

batch## 2
grad[0]: tensor([ 0.0000e+00, -1.8092e-04, -2.6775e-06,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1]: tensor([1.2320e-06, 1.4598e-07, 6.5203e-06,  ..., 1.8312e-06, 5.5325e-07,
        3.4233e-07])

***batch_idx -- n workers***: 2
grads[0]: tensor([ 0.0000e+00, -1.8092e-04, -2.6775e-06,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grads[1]: tensor([1.2320e-06, 1.4598e-07, 6.5203e-06,  ..., 1.8312e-06, 5.5325e-07,
        3.4233e-07])

batch## 3
grad[0]: tensor([ 0.0005, -0.0005,  0.0003,  ...,  0.0000,  0.0000,  0.0000])
grad[1]: tensor([-1.4754e-06, -4.0035e-07,  2.7690e-06,  ...,  7.6445e-07,
         5.4792e-07,  7.8338e-07])

batch## 4
grad[0]: tensor([ 3.5858e-04, -5.7134e-04,  5.8716e-05,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1]: tensor([-7.6018e-07,  1.0116e-06, -7.6559e-07,  ..., -1.0264e-06,
        -1.9291e-08, -6.5787e-07])

***batch_idx -- n workers***: 4
grads[0]: tensor([ 3.5858e-04, -5.7134e-04,  5.8716e-05,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grads[1]: tensor([-7.6018e-07,  1.0116e-06, -7.6559e-07,  ..., -1.0264e-06,
        -1.9291e-08, -6.5787e-07])

batch## 5
grad[0]: tensor([ 3.0114e-04, -2.1489e-04,  2.2084e-05,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1]: tensor([ 4.3411e-06,  2.4919e-06, -2.8566e-07,  ..., -5.3880e-07,
         2.8594e-06,  2.0201e-07])

batch## 6
grad[0]: tensor([6.2217e-05, 1.6216e-04, 1.0129e-05,  ..., 0.0000e+00, 0.0000e+00,
        0.0000e+00])
grad[1]: tensor([1.3991e-06, 3.2700e-06, 6.8595e-07,  ..., 7.9697e-07, 8.8303e-06,
        2.2207e-08])

***batch_idx -- n workers***: 6
grads[0]: tensor([6.2217e-05, 1.6216e-04, 1.0129e-05,  ..., 0.0000e+00, 0.0000e+00,
        0.0000e+00])
grads[1]: tensor([1.3991e-06, 3.2700e-06, 6.8595e-07,  ..., 7.9697e-07, 8.8303e-06,
        2.2207e-08])

batch## 7
grad[0]: tensor([-9.4372e-06,  7.5028e-05,  4.6864e-06,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1]: tensor([1.0020e-06, 1.1829e-06, 5.2876e-07,  ..., 3.6874e-07, 7.7666e-06,
        4.6160e-08])

batch## 8
grad[0]: tensor([ 1.7549e-04,  3.8375e-05, -3.1536e-04,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grad[1]: tensor([-2.6188e-06,  6.0699e-06,  4.2311e-06,  ...,  3.7136e-06,
         1.0075e-05,  2.6129e-06])

***batch_idx -- n workers***: 8
grads[0]: tensor([ 1.7549e-04,  3.8375e-05, -3.1536e-04,  ...,  0.0000e+00,
         0.0000e+00,  0.0000e+00])
grads[1]: tensor([-2.6188e-06,  6.0699e-06,  4.2311e-06,  ...,  3.7136e-06,
         1.0075e-05,  2.6129e-06])
Train perplexity at epoch 0:    37.46
Epoch Size=  8
Validation perplexity at epoch 0:    32.97
==================================================
|                    Testing                     |
==================================================
Epoch Size=  36
Test Perplexity:    33.86

======================== Done! ========================
