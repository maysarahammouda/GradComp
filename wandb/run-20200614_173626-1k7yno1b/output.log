Vocabluary size: 39
==================================================
|                    Training                    |
==================================================
Epoch Size=  4
############# 1
grad length: 11
grad[1]: tensor([-0.0002, -0.0005, -0.0006,  ...,  0.0000,  0.0000,  0.0000])
grad[1].shape: torch.Size([1170])
Traceback (most recent call last):
  File "main.py", line 184, in <module>
    train_ppl = run_epoch(model, train_data, True, lr)
  File "main.py", line 128, in run_epoch
    print ("grad[0]+grad[1]:", grad[0]+grad[1])
RuntimeError: The size of tensor a (1170) must match the size of tensor b (3600) at non-singleton dimension 0
